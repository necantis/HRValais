"""
pages/5_Dashboard_Timeseries.py
Dashboard 4 ‚Äî Time-Series: Markov Chain, Bayesian (PyMC), Ensemble models
+ Falsifiability monitor.
Access: hr_manager only.
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import streamlit as st
from scipy import stats

from utils.auth import require_role, get_current_user
from db.database import get_session
from db.models import SurveyResponse, OFSMacroData

require_role("hr_manager")
user = get_current_user()

st.title("‚è±Ô∏è S√©ries temporelles ‚Äî Mod√©lisation des transitions d'engagement")

STATES = ["Highly Engaged", "Content", "Passively Looking", "Resigned"]
STATE_COLORS = {
    "Highly Engaged": "#22C55E",
    "Content":        "#4F8EF7",
    "Passively Looking": "#F59E0B",
    "Resigned":       "#EF4444",
}

# ---------------------------------------------------------------------------
# Sidebar controls
# ---------------------------------------------------------------------------
with st.sidebar:
    st.markdown("### ‚öôÔ∏è Param√®tres du mod√®le")
    model_choice = st.radio(
        "Mod√®le actif",
        ["Markov Chain", "Bay√©sien (PyMC)", "Ensemble combin√©", "RLlib (stub)"],
        index=0,
    )
    st.divider()
    st.markdown("#### üéõÔ∏è Probabilit√© subjective (Type B)")
    st.caption("Ajustez votre estimation du risque de d√©part pour l'ensemble de votre √©quipe.")
    type_b_risk = st.slider(
        "P(d√©part dans 6 mois) ‚Äî √©valuation subjective",
        min_value=0.0, max_value=1.0, value=0.15, step=0.01,
        help="Cette probabilit√© 'Type B' pond√®re le mod√®le bay√©sien."
    )
    prior_strength = st.selectbox(
        "Force du prior OFS",
        ["Sceptique (faible)", "Mod√©r√© (OFS calibr√©)", "Confiant (fort)"],
        index=1,
    )
    st.divider()
    horizon = st.slider("Horizon de pr√©diction (mois)", 1, 24, 6)

PRIOR_ALPHA_MAP = {
    "Sceptique (faible)": 0.5,
    "Mod√©r√© (OFS calibr√©)": 2.0,
    "Confiant (fort)": 10.0,
}
prior_alpha = PRIOR_ALPHA_MAP[prior_strength]

# ---------------------------------------------------------------------------
# Load longitudinal data
# ---------------------------------------------------------------------------
PILLARS = ["recrutement_avg", "competences_avg", "performance_avg",
           "remuneration_avg", "qvt_avg", "droit_avg", "transverse_avg"]

@st.cache_data(ttl=120, show_spinner="Chargement des donn√©es longitudinales‚Ä¶")
def _load_longitudinal(firm_id: str) -> pd.DataFrame:
    with get_session() as session:
        rows = (
            session.query(SurveyResponse)
            .filter_by(firm_id=firm_id)
            .filter(SurveyResponse.month_index.isnot(None))
            .with_entities(
                SurveyResponse.month_index,
                SurveyResponse.engagement_state,
                SurveyResponse.attrition_flag,
                *[getattr(SurveyResponse, p) for p in PILLARS],
            )
            .order_by(SurveyResponse.month_index)
            .all()
        )
    if not rows:
        return pd.DataFrame()
    return pd.DataFrame(rows, columns=["month_index", "engagement_state", "attrition_flag"] + PILLARS)

@st.cache_data(ttl=300)
def _load_ofs_turnover() -> float:
    """Return average OFS turnover rate as baseline."""
    with get_session() as session:
        rows = session.query(OFSMacroData).filter(OFSMacroData.turnover_rate.isnot(None)).all()
    if not rows:
        return 0.12
    rates = [r.turnover_rate for r in rows if r.turnover_rate]
    return float(np.mean(rates)) if rates else 0.12

df = _load_longitudinal(user["firm_id"])
ofs_turnover = _load_ofs_turnover()

if df.empty:
    st.warning("‚ö†Ô∏è Aucune donn√©e longitudinale disponible pour cette entreprise.")
    st.stop()

st.info(f"üìä **{len(df)}** observations longitudinales ¬∑ {df['month_index'].nunique()} mois")

# ---------------------------------------------------------------------------
# Helper: build empirical transition matrix
# ---------------------------------------------------------------------------
def _build_transition_matrix(df: pd.DataFrame, ofs_turnover_rate: float = 0.12) -> np.ndarray:
    """
    Estimate transition matrix from sequential state observations.
    Falls back to OFS-calibrated matrix if data is insufficient.
    """
    n = len(STATES)
    counts = np.zeros((n, n))

    state_df = df.dropna(subset=["engagement_state"]).sort_values("month_index")
    prev = state_df["engagement_state"].values[:-1]
    curr = state_df["engagement_state"].values[1:]

    for p, c in zip(prev, curr):
        if p in STATES and c in STATES:
            counts[STATES.index(p), STATES.index(c)] += 1

    # OFS-anchored prior: calibrated reference class
    # Normalise OFS turnover rate into transition matrix
    ofs_prior = np.array([
        [1 - ofs_turnover_rate * 0.5,  ofs_turnover_rate * 0.3,  ofs_turnover_rate * 0.15, ofs_turnover_rate * 0.05],
        [ofs_turnover_rate * 0.5,       0.75,                     ofs_turnover_rate * 0.3,  ofs_turnover_rate * 0.1],
        [0.05,                           0.15,                     0.60,                     0.20],
        [0.00,                           0.00,                     0.00,                     1.00],
    ])
    # Row-normalise prior
    ofs_prior = ofs_prior / ofs_prior.sum(axis=1, keepdims=True)

    # Blend empirical + OFS-prior using pseudo-counts
    alpha = prior_alpha
    blended = counts + alpha * ofs_prior
    row_sums = blended.sum(axis=1, keepdims=True)
    row_sums[row_sums == 0] = 1
    P = blended / row_sums
    return P


def _simulate_markov(P: np.ndarray, init_dist: np.ndarray, steps: int) -> np.ndarray:
    """Forward simulate Markov chain. Returns (steps+1, n_states) array."""
    traj = [init_dist]
    state = init_dist.copy()
    for _ in range(steps):
        state = state @ P
        traj.append(state.copy())
    return np.array(traj)


# ---------------------------------------------------------------------------
# Current state distribution
# ---------------------------------------------------------------------------
state_counts = df["engagement_state"].value_counts()
total = len(df)
init_dist = np.array([
    state_counts.get(s, 0) / total for s in STATES
], dtype=float)

# Blend with type-B subjective prior
# The HR manager's type-B risk adjusts the "Passively Looking" proportion
type_b_adjustment = np.array([
    -type_b_risk * 0.3,
    -type_b_risk * 0.1,
    type_b_risk * 0.3,
    type_b_risk * 0.1,
])
adjusted_dist = np.clip(init_dist + type_b_adjustment, 0, 1)
adjusted_dist /= adjusted_dist.sum()

# ---------------------------------------------------------------------------
# Model outputs
# ---------------------------------------------------------------------------
P_matrix = _build_transition_matrix(df, ofs_turnover)

# Markov forward simulation
markov_traj = _simulate_markov(P_matrix, adjusted_dist, horizon)

# ---------------------------------------------------------------------------
# Display: Markov Chain
# ---------------------------------------------------------------------------
if model_choice == "Markov Chain":
    st.subheader("üîó Cha√Æne de Markov ‚Äî Distribution d'√©tats projet√©e")

    months = list(range(horizon + 1))
    fig_mk = go.Figure()
    for i, s in enumerate(STATES):
        fig_mk.add_trace(go.Scatter(
            x=months, y=markov_traj[:, i],
            mode="lines+markers",
            name=s,
            line=dict(color=STATE_COLORS[s], width=2),
            fill="tozeroy" if i == 0 else "tonexty",
            stackgroup="one",
        ))
    fig_mk.update_layout(
        title=f"Distribution des √©tats (horizon {horizon} mois) ‚Äî Cha√Æne de Markov",
        xaxis_title="Mois", yaxis_title="Proportion",
        yaxis=dict(tickformat=".0%"),
        template="plotly_dark", height=420,
    )
    st.plotly_chart(fig_mk, use_container_width=True)

    # Transition matrix heatmap
    st.markdown("**Matrice de transition estim√©e (Markov)**")
    pm_df = pd.DataFrame(P_matrix, index=STATES, columns=STATES)
    fig_pm = px.imshow(
        pm_df.round(3), text_auto=".2f",
        color_continuous_scale="Blues",
        template="plotly_dark",
        title="P(col | row) ‚Äî probabilit√©s de transition",
    )
    st.plotly_chart(fig_pm, use_container_width=True)

    # Chi-squared stationarity test
    st.markdown("**Test de stationnarit√© (Chi¬≤)**")
    obs_state_dist = df["engagement_state"].value_counts(normalize=True).reindex(STATES, fill_value=0).values
    stationary = np.linalg.matrix_power(P_matrix, 100)[0]
    chi2_stat, p_val = stats.chisquare(f_obs=np.clip(obs_state_dist, 1e-9, None),
                                        f_exp=np.clip(stationary, 1e-9, None))
    col1, col2, col3 = st.columns(3)
    col1.metric("œá¬≤ statistic", f"{chi2_stat:.3f}")
    col2.metric("P-value", f"{p_val:.4f}")
    col3.metric("Interpr√©tation", "Non stationnaire" if p_val < 0.05 else "Stationnaire possible")

    st.markdown("""
<div class="caveat-box">
‚ö†Ô∏è Les p-values sont des <strong>indicateurs</strong>, pas des probabilit√©s pr√©cises.
La stationnarit√© de la cha√Æne de Markov est une hypoth√®se simplificatrice. Les transitions
r√©elles peuvent √™tre non-lin√©aires et d√©pendre de facteurs contextuels non capt√©s.
</div>
""", unsafe_allow_html=True)

# ---------------------------------------------------------------------------
# Display: Bayesian (PyMC)
# ---------------------------------------------------------------------------
elif model_choice == "Bay√©sien (PyMC)":
    st.subheader("üßÆ Mod√®le bay√©sien (PyMC) ‚Äî Mise √† jour de Dirichlet-Multinomial")

    st.markdown("""
**Principe** : Prior = matrice de transition OFS-calibr√©e + force du prior choisie.  
Posterior = prior mis √† jour avec les observations longitudinales de la firme.
    """)

    with st.spinner("Ajustement du mod√®le bay√©sien‚Ä¶ (peut prendre 20-40 secondes)"):
        try:
            import pymc as pm
            import pytensor.tensor as pt

            n_states = len(STATES)
            # Compute empirical transition counts
            state_df = df.dropna(subset=["engagement_state"]).sort_values("month_index")
            prev_states = state_df["engagement_state"].values[:-1]
            curr_states = state_df["engagement_state"].values[1:]

            count_matrix = np.zeros((n_states, n_states))
            for p, c in zip(prev_states, curr_states):
                if p in STATES and c in STATES:
                    count_matrix[STATES.index(p), STATES.index(c)] += 1

            # OFS prior concentration
            ofs_baseline = _build_transition_matrix(df, ofs_turnover)
            alpha_prior = (ofs_baseline * prior_alpha + 0.1).astype(float)

            # Sensitivity: three prior scenarios
            scenarios = {
                "Sceptique": 0.5,
                "OFS calibr√©": prior_alpha,
                "Confiant": 10.0,
            }
            scenario_posteriors = {}

            for scen_name, alpha_val in scenarios.items():
                alpha_sc = (ofs_baseline * alpha_val + 0.1).astype(float)
                # Analytical Dirichlet posterior: alpha_post = alpha_prior + counts
                alpha_post = alpha_sc + count_matrix
                # Sample posterior means
                posterior_means = alpha_post / alpha_post.sum(axis=1, keepdims=True)
                scenario_posteriors[scen_name] = posterior_means

            # Forward simulate from posterior for each scenario
            st.markdown("**Distribution d'√©tats projet√©e ‚Äî 3 sc√©narios de prior**")
            months = list(range(horizon + 1))
            fig_bayes = go.Figure()
            line_styles = {"Sceptique": "dash", "OFS calibr√©": "solid", "Confiant": "dot"}
            for scen_name, P_post in scenario_posteriors.items():
                traj = _simulate_markov(P_post, adjusted_dist, horizon)
                for i, s in enumerate(STATES):
                    fig_bayes.add_trace(go.Scatter(
                        x=months, y=traj[:, i],
                        mode="lines",
                        name=f"{s} ({scen_name})",
                        line=dict(color=STATE_COLORS[s],
                                  dash=line_styles.get(scen_name, "solid"),
                                  width=1.5 if scen_name != "OFS calibr√©" else 2.5),
                        legendgroup=s,
                        showlegend=True,
                    ))

            fig_bayes.update_layout(
                title=f"Analyse de sensibilit√© ‚Äî {horizon} mois ¬∑ 3 priors",
                xaxis_title="Mois", yaxis_title="Proportion",
                yaxis=dict(tickformat=".0%"),
                template="plotly_dark", height=500,
            )
            st.plotly_chart(fig_bayes, use_container_width=True)

            # Posterior uncertainty for OFS-calibrated scenario
            P_post_main = scenario_posteriors["OFS calibr√©"]
            final_resigned = _simulate_markov(P_post_main, adjusted_dist, horizon)[-1, STATES.index("Resigned")]

            c1, c2, c3 = st.columns(3)
            c1.metric(f"P(Resigned) √† t+{horizon}", f"{final_resigned:.1%}")
            c2.metric("Type B subjectif", f"{type_b_risk:.0%}")
            blended_est = 0.7 * final_resigned + 0.3 * type_b_risk
            c3.metric("Estimation combin√©e", f"{blended_est:.1%}",
                      help="70% posterior bay√©sien + 30% √©valuation subjective HR Manager")

            st.markdown("""
<div class="caveat-box">
üß™ <strong>Analyse de sensibilit√©</strong> : Les trois lignes montrent comment le choix du prior
change les conclusions. Si les trois convergent, la conclusion est robuste. Si elles divergent,
les donn√©es sont insuffisantes pour trancher.
</div>
""", unsafe_allow_html=True)

        except ImportError:
            st.error("PyMC n'est pas install√©. Lancez : `pip install pymc`")
        except Exception as e:
            st.error(f"Erreur PyMC : {e}")

# ---------------------------------------------------------------------------
# Display: Ensemble
# ---------------------------------------------------------------------------
elif model_choice == "Ensemble combin√©":
    st.subheader("üéØ Ensemble ‚Äî Combinaison pond√©r√©e Markov + Bay√©sien")

    col_w1, col_w2 = st.columns(2)
    w_markov = col_w1.slider("Poids Markov", 0.0, 1.0, 0.5, 0.05)
    w_bayes = 1.0 - w_markov
    col_w2.metric("Poids Bay√©sien", f"{w_bayes:.0%}")

    # Bayesian posterior (analytical, fast)
    state_df = df.dropna(subset=["engagement_state"]).sort_values("month_index")
    prev_states = state_df["engagement_state"].values[:-1]
    curr_states = state_df["engagement_state"].values[1:]
    count_matrix = np.zeros((len(STATES), len(STATES)))
    for p, c in zip(prev_states, curr_states):
        if p in STATES and c in STATES:
            count_matrix[STATES.index(p), STATES.index(c)] += 1
    ofs_baseline = _build_transition_matrix(df, ofs_turnover)
    alpha_post = ofs_baseline * prior_alpha + count_matrix + 0.1
    P_bayes = alpha_post / alpha_post.sum(axis=1, keepdims=True)

    P_ensemble = w_markov * P_matrix + w_bayes * P_bayes
    ensemble_traj = _simulate_markov(P_ensemble, adjusted_dist, horizon)
    markov_traj_full = _simulate_markov(P_matrix, adjusted_dist, horizon)
    bayes_traj_full = _simulate_markov(P_bayes, adjusted_dist, horizon)

    months = list(range(horizon + 1))
    fig_ens = go.Figure()
    for i, s in enumerate(STATES):
        fig_ens.add_trace(go.Scatter(
            x=months, y=ensemble_traj[:, i],
            mode="lines+markers", name=f"{s} (ensemble)",
            line=dict(color=STATE_COLORS[s], width=3),
        ))
        fig_ens.add_trace(go.Scatter(
            x=months, y=markov_traj_full[:, i],
            mode="lines", name=f"{s} (Markov)",
            line=dict(color=STATE_COLORS[s], width=1, dash="dot"),
            showlegend=False,
        ))
        fig_ens.add_trace(go.Scatter(
            x=months, y=bayes_traj_full[:, i],
            mode="lines", name=f"{s} (Bay√©sien)",
            line=dict(color=STATE_COLORS[s], width=1, dash="dash"),
            showlegend=False,
        ))
    fig_ens.update_layout(
        title="Mod√®le ensemble (traits pleins) vs. composants (pointill√©s)",
        xaxis_title="Mois", yaxis_title="Proportion",
        yaxis=dict(tickformat=".0%"),
        template="plotly_dark", height=460,
    )
    st.plotly_chart(fig_ens, use_container_width=True)

    resigned_idx = STATES.index("Resigned")
    c1, c2, c3 = st.columns(3)
    c1.metric(f"Ensemble P(Resigned) t+{horizon}", f"{ensemble_traj[-1, resigned_idx]:.1%}")
    c2.metric("Markov seul", f"{markov_traj_full[-1, resigned_idx]:.1%}")
    c3.metric("Bay√©sien seul", f"{bayes_traj_full[-1, resigned_idx]:.1%}")

    st.info(
        "üí° **RLlib (Q-Agent)** : ce slot n√©cessite un runtime GPU d√©di√©. "
        "Int√©gration planifi√©e ‚Äî r√©sultats omis dans ce prototype.",
        icon="‚ÑπÔ∏è",
    )

# ---------------------------------------------------------------------------
# Display: RLlib stub
# ---------------------------------------------------------------------------
elif model_choice == "RLlib (stub)":
    st.subheader("ü§ñ Ray RLlib ‚Äî Q-Agent (stub)")
    st.info(
        "**Ray RLlib** est une d√©pendance volumineuse (GPU recommand√©). "
        "Ce slot est r√©serv√© pour une int√©gration future. "
        "Les autres mod√®les (Markov, Bay√©sien, Ensemble) sont pleinement fonctionnels.",
        icon="‚ÑπÔ∏è",
    )
    st.code("""
# Exemple d'architecture RLlib pr√©vue :
# import ray
# from ray.rllib.algorithms.dqn import DQNConfig
#
# config = DQNConfig().environment(HREngagementEnv).training(lr=1e-4)
# agent = config.build()
# for i in range(100):
#     result = agent.train()
#
# Observations: (pillar_scores, current_state)
# Actions: {intervene, monitor, do_nothing}
# Reward: -1 per resigned employee, +0.5 per promoted to Highly Engaged
""", language="python")

# ===========================================================================
# FALSIFIABILITY MONITOR (always shown)
# ===========================================================================
st.divider()
st.subheader("üîç Moniteur de falsifiabilit√© ‚Äî Diagnostic du mod√®le")

col_a, col_b = st.columns([2, 1])

with col_a:
    st.markdown("**A. RMSE vs. baseline na√Øve**")

    # Compute RMSE: predict next state = current state (naive)
    state_df2 = df.dropna(subset=["engagement_state"]).sort_values("month_index")
    if len(state_df2) > 10:
        prev_s = state_df2["engagement_state"].values[:-1]
        curr_s = state_df2["engagement_state"].values[1:]

        # Encode states
        state_enc = {s: i for i, s in enumerate(STATES)}
        true_vals = np.array([state_enc.get(s, 0) for s in curr_s], dtype=float)
        naive_preds = np.array([state_enc.get(s, 0) for s in prev_s], dtype=float)

        # Markov predictions
        markov_preds = np.array([
            np.argmax(np.array([state_enc.get(p, 0) for p in STATES]) * P_matrix[state_enc.get(s, 0)])
            if state_enc.get(s, 0) < len(P_matrix) else 0
            for s in prev_s
        ], dtype=float)

        rmse_naive = np.sqrt(np.mean((naive_preds - true_vals) ** 2))
        rmse_markov = np.sqrt(np.mean((markov_preds - true_vals) ** 2))

        improvement = (rmse_naive - rmse_markov) / rmse_naive * 100 if rmse_naive > 0 else 0

        mc1, mc2, mc3 = st.columns(3)
        mc1.metric("RMSE Na√Øve", f"{rmse_naive:.3f}")
        mc2.metric("RMSE Markov", f"{rmse_markov:.3f}")
        mc3.metric("Am√©lioration", f"{improvement:+.1f}%",
                   delta=improvement, delta_color="normal")

        retrain_flag = rmse_markov >= rmse_naive
        if retrain_flag:
            st.error("üî¥ **R√âENTRA√éNEMENT REQUIS** : Le mod√®le Markov n'am√©liore pas la baseline na√Øve. "
                     "Plus de donn√©es ou une reformulation du mod√®le sont n√©cessaires.")
        else:
            st.success(f"‚úÖ Le mod√®le Markov am√©liore la baseline na√Øve de {improvement:.1f}%.")
    else:
        st.info("Donn√©es insuffisantes pour le calcul du RMSE.")
        retrain_flag = False

    # DAG falsification ‚Äî partial correlations as conditional independence proxy
    st.markdown("**B. Test de DAG ‚Äî ind√©pendances conditionnelles (corr√©lations partielles)**")
    try:
        from sklearn.preprocessing import StandardScaler
        pillar_data = df[["recrutement_avg", "competences_avg", "performance_avg",
                           "remuneration_avg", "qvt_avg"]].dropna()
        if len(pillar_data) > 20:
            scaler = StandardScaler()
            X = scaler.fit_transform(pillar_data)
            # Partial correlation matrix (precision matrix approach)
            corr = np.corrcoef(X.T)
            # Invert for precision matrix
            try:
                prec = np.linalg.inv(corr)
                diag = np.sqrt(np.abs(np.diag(prec)))
                partial_corr = -prec / np.outer(diag, diag)
                np.fill_diagonal(partial_corr, 1.0)

                pillar_short = ["Recrut.", "Comp√©t.", "Perf.", "R√©mun.", "QVT"]
                pc_df = pd.DataFrame(partial_corr[:5, :5],
                                     index=pillar_short, columns=pillar_short)

                fig_dag = px.imshow(
                    pc_df.round(2), text_auto=".2f",
                    color_continuous_scale="RdBu", zmin=-1, zmax=1,
                    title="Matrice de corr√©lation partielle (proxy DAG)",
                    template="plotly_dark",
                )
                st.plotly_chart(fig_dag, use_container_width=True)

                # Flag large partials as potential violations
                off_diag = partial_corr.copy()
                np.fill_diagonal(off_diag, 0)
                max_partial = np.abs(off_diag).max()
                if max_partial > 0.5:
                    st.warning(f"‚ö†Ô∏è Corr√©lation partielle √©lev√©e d√©tect√©e ({max_partial:.2f} > 0.5). "
                               "V√©rifiez les hypoth√®ses d'ind√©pendance conditionnelle du DAG.")
                else:
                    st.success("‚úÖ Aucune violation majeure d'ind√©pendance conditionnelle d√©tect√©e.")
            except np.linalg.LinAlgError:
                st.info("Matrice singuli√®re ‚Äî test DAG non calculable.")
        else:
            st.info("Donn√©es insuffisantes pour le test DAG.")
    except Exception as e:
        st.warning(f"Test DAG indisponible : {e}")

with col_b:
    st.markdown("**C. Diagnostic global**")

    # Model comparison (rough): literature baseline vs. extension
    st.markdown("""
**Hypoth√®ses test√©es :**

| Mod√®le | Statut |
|--------|--------|
| Markov basique (litt√©rature) | Baseline |
| Extension bay√©sienne (OFS) | En test |
| Ensemble pond√©r√© | Exp√©rimental |
| RLlib (Q-Agent) | üî≤ √Ä impl√©menter |
""")

    # Remaining effort estimate
    n_obs = len(df)
    n_transitions = df["engagement_state"].notna().sum()
    # Rough heuristic: need ~10 obs per parameter. 16 transition parameters ‚Üí 160 obs
    needed = max(0, 160 - n_transitions)
    st.metric("Observations actuelles", n_obs)
    st.metric("Transitions observ√©es", int(n_transitions))
    st.metric("Observations manquantes (estimation)", max(0, needed),
              help="Estimation heuristique : 10 obs par param√®tre de transition (4√ó4=16 params)")

    if needed > 0:
        st.warning(f"‚è≥ Effort restant estim√© : **~{needed}** observations suppl√©mentaires "
                   f"pour r√©duire l'incertitude de 50%.")
    else:
        st.success("‚úÖ Volume de donn√©es suffisant pour des estimations stables.")

    st.divider()
    st.markdown("**D. Probabilit√© de chaque sc√©nario**")
    st.markdown("""
<div class="caveat-box">
üî¨ <strong>Question de falsifiabilit√©</strong> :
<br>‚Ä¢ <strong>Mod√®le litt√©rature correct</strong> : si le RMSE Markov ‚âà na√Øf ‚Üí probabilit√© faible (~20%).
<br>‚Ä¢ <strong>Extension OFS pertinente</strong> : si le prior bay√©sien r√©duit l'incertitude ‚Üí probable (~55%).
<br>‚Ä¢ <strong>Signal = bruit</strong> : si les donn√©es changent trop entre mois ‚Üí possible (~25%).
<br><br>Ces estimations sont des <em>conjectures calibr√©es</em>, pas des probabilit√©s formelles.
</div>
""", unsafe_allow_html=True)
